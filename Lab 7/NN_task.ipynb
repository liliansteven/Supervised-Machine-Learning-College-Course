{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Load MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 28, 28)\n",
      "Y_train: (60000,)\n",
      "X_test:  (10000, 28, 28)\n",
      "Y_test:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "#loading\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    " \n",
    "#shape of dataset\n",
    "print('X_train: ' + str(X_train.shape))\n",
    "print('Y_train: ' + str(Y_train.shape))\n",
    "print('X_test:  '  + str(X_test.shape))\n",
    "print('Y_test:  '  + str(Y_test.shape))\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting\n",
    "for i in range(1):  \n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    pyplot.imshow(X_train[i], cmap=pyplot.get_cmap('gray'))\n",
    "    pyplot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Standardize your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n"
     ]
    }
   ],
   "source": [
    "mean_train = np.mean(X_train, axis=0)\n",
    "std_train = np.std(X_train, axis=0)\n",
    "std_train[std_train == 0] = 1e-9\n",
    "X_train = (X_train - mean_train) / std_train\n",
    "\n",
    "mean_test = np.mean(X_test, axis=0)\n",
    "std_test = np.std(X_test, axis=0)\n",
    "std_test[std_test == 0] = 1e-9\n",
    "X_test = (X_test - mean_test) / std_test\n",
    "\n",
    "X_data = np.concatenate((X_train, X_test), axis=0)\n",
    "y_data = np.concatenate((Y_train, Y_test), axis=0)\n",
    "\n",
    "X_data = X_data.reshape(X_data.shape[0],-1)\n",
    "print(X_data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Implement Logistic Regression with different values for learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic_Regression():\n",
    "    \n",
    "    \n",
    "    # declaring learning rate & number of iterations (Hyperparametes)\n",
    "    def __init__(self, learning_rate, no_of_iterations):\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.no_of_iterations = no_of_iterations\n",
    "        \n",
    "        \n",
    "    # fit function to train the model with dataset\n",
    "    def fit(self, X, Y):\n",
    "        \n",
    "        # number of data points in the dataset (number of rows)  -->  m\n",
    "        # number of input features in the dataset (number of columns)  --> n\n",
    "        self.m, self.n = X.shape\n",
    "        \n",
    "        #initiating weight & bias value\n",
    "        self.w = np.zeros(self.n)\n",
    "        self.b = 0\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "        # implementing Gradient Descent for Optimization\n",
    "        for i in range(self.no_of_iterations):\n",
    "            self.update_weights()       \n",
    "        \n",
    "        return  self.w\n",
    "    \n",
    "\n",
    "    def update_weights(self):\n",
    "        # Y_hat formula (sigmoid function)\n",
    "        Y_hat = 1 / (1 + np.exp( - (self.X.dot(self.w) + self.b ) ))    \n",
    "        \n",
    "        # derivaties\n",
    "        dw = (1/self.m)*np.dot(self.X.T, (Y_hat - self.Y))\n",
    "        \n",
    "        db = (1/self.m)*np.sum(Y_hat - self.Y)\n",
    "        \n",
    "        # updating the weights & bias using gradient descent\n",
    "        self.w = self.w - self.learning_rate * dw\n",
    "        \n",
    "        self.b = self.b - self.learning_rate * db\n",
    "      \n",
    "    # Sigmoid Equation & Decision Boundary\n",
    "    def predict(self, X):\n",
    "        Y_pred = 1 / (1 + np.exp( - (X.dot(self.w) + self.b ) ))\n",
    "        Y_pred = np.where( Y_pred > 0.5, 1, 0)\n",
    "        return Y_pred\n",
    "    \n",
    "\n",
    "    def score(self,y,y_hat):\n",
    "        tp,tn,fp,fn = 0,0,0,0\n",
    "        for i in range(len(y)):\n",
    "            if y[i] == 1 and y_hat[i] == 1:\n",
    "                tp += 1\n",
    "            elif y[i] == 1 and y_hat[i] == 0:\n",
    "                fn += 1\n",
    "            elif y[i] == 0 and y_hat[i] == 1:\n",
    "                fp += 1\n",
    "            elif y[i] == 0 and y_hat[i] == 0:\n",
    "                tn += 1\n",
    "        precision = tp/(tp+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        score = 2*precision*recall/(precision+recall)\n",
    "        return score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## onehotercoder :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9\n",
       "0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "1  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "2  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "3  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc_ydata = pd.DataFrame(enc.fit_transform(y_data.reshape(-1,1)).toarray())\n",
    "enc_ydata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.model_selection import train_test_split\n",
    "\n",
    "X_data = pd.DataFrame(X_data)\n",
    "x_train , x_test ,y_train , y_test = train_test_split(X_data, enc_ydata ,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Logistic_Regression(learning_rate= 0.001,no_of_iterations=1000)\n",
    "weights = np.zeros((10,784))\n",
    "for i in range (10):\n",
    "    Y = enc_ydata[i]\n",
    "    weights[i ,:] = model.fit(x_train,y_train[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0276667 , -0.91433069, -0.8640698 , ..., -0.56865529,\n",
       "         4.16396674,  3.23103116],\n",
       "       [-0.22017022, -0.15106092,  0.73270443, ...,  3.13299103,\n",
       "        -0.89264242,  0.13158279],\n",
       "       [-0.8325581 , -0.14883055, -1.00238705, ..., -0.61129328,\n",
       "        -0.50162398,  0.55546448],\n",
       "       ...,\n",
       "       [-0.63977851,  0.05692614, -0.51266291, ..., -0.21595362,\n",
       "        -0.97227397, -1.54560986],\n",
       "       [-0.24367844,  0.29881625,  0.66879926, ..., -0.28170397,\n",
       "        -0.4057928 ,  0.11852999],\n",
       "       [-0.44350249,  0.0718324 ,  0.36672323, ..., -0.0542103 ,\n",
       "        -0.48804859, -1.071099  ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = np.zeros((10,len(y_train)))\n",
    "for i in range (10):\n",
    "    Z[i,:] = x_train.dot(weights[i,:])\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: \n",
      "[6 4 1 ... 1 0 0]\n",
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "New predicted class: \n",
      "     0    1    2    3    4    5    6    7    8    9\n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
      "1  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
      "2  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "3  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "Accuracy of class(0):  97.72857142857143\n",
      "Accuracy of class(1):  96.10892857142858\n",
      "Accuracy of class(2):  96.95357142857142\n",
      "Accuracy of class(3):  96.00892857142857\n",
      "Accuracy of class(4):  97.52678571428571\n",
      "Accuracy of class(5):  95.94821428571429\n",
      "Accuracy of class(6):  97.78750000000001\n",
      "Accuracy of class(7):  96.52857142857142\n",
      "Accuracy of class(8):  96.03035714285714\n",
      "Accuracy of class(9):  95.95\n"
     ]
    }
   ],
   "source": [
    "softmax_values = np.exp(Z) / np.sum(np.exp(Z), axis=0)\n",
    "\n",
    "predicted_class = np.argmax(softmax_values, axis=0)\n",
    "\n",
    "print(\"predicted class: \")\n",
    "print(predicted_class)\n",
    "print(\"\\n\",\"-\"*50,\"\\n\")\n",
    "\n",
    "predicted_class = pd.DataFrame(enc.fit_transform(predicted_class.reshape(-1,1)).toarray())\n",
    "print(\"New predicted class: \")\n",
    "print(predicted_class.head(5))\n",
    "print(\"\\n\",\"-\"*50,\"\\n\")\n",
    "\n",
    "for i in range (10):\n",
    "    accuracy = np.mean(predicted_class.iloc[:, i].values == y_train[i]) * 100\n",
    "    print(f\"Accuracy of class({i}): \",accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
